{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertoarturomc/ProgramacionConcurrente/blob/main/Examen_Final_Parte_2_Version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Examen Final, Parte 2\n",
        "\n",
        "¡Muchas felicitaciones por haber llegado hasta aquí! Este será el último ejercicio que tendrás que hacer en esta clase.\n",
        "\n",
        "Para realizarlo, crea un programa que haga las siguientes instrucciones. Al finalizar, descarga el archivo en formato .ipynb y cárgalo en Blackboard.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "a) En la primer celda, sólo escribe tu ID. Me servirá como referencia.\n",
        "\n",
        "b) Después, crea un programa de Spark, el cuál deberá cumplir con las siguientes tareas, **dependiendo de cada uno de los valores de tu ID**.\n",
        "\n",
        "Ejemplo: el ID de estudiante del profesor era \"143915\". Entonces, mi programa debe hacer la tarea 1, la 4, la 3, la 9, la 1 y la 5, **en ese orden**. Como mi ID tiene dos \"1\", la segunda vez deberé tomar la segunda tarea especificada. Si mi ID tuviera 3 o más \"1\", ¡felicidades! Ya no tengo que hacer nada más.\n",
        "\n",
        "Estaremos trabajando con este Dataset:\n",
        "https://www.kaggle.com/datasets/victorsoeiro/netflix-tv-shows-and-movies?select=titles.csv\n",
        "\n",
        "Nota cómo tiene dos tablas: 'credits' y 'titles'.\n"
      ],
      "metadata": {
        "id": "cIP21vrKQXPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tareas:\n",
        "\n",
        "1: Lee correctamente el archivo 'titles.csv' en un DataFrame de Spark.\n",
        "*   1, segunda aparición: Ordena de manera descendiente según \"release_year\".\n",
        "\n",
        "2: Filtra y quédate con sólo las películas con runtime mayor a 60.\n",
        "* 2, segunda aparición: Ordena de manera ascendente según \"id\".\n",
        "\n",
        "3: Filtra y quédate con sólo las películas con runtime menor a 120.\n",
        "* 3, segunda aparición: Ordena de manera ascendente según \"release year\".\n",
        "\n",
        "4: Quita la columna \"production_countries\".\n",
        "* 4, segunda aparición: Ordena de manera descendente según \"id\".\n",
        "\n",
        "5: Quita la columna \"imdb_votes\"\n",
        "* 5, segunda aparición: Ordena de manera descendente según \"runtime\".\n",
        "\n",
        "6: Cambia el tipo de Dato de \"seasons\". No importa a qué lo cambies, mientras se cambie el tipo de Dato.\n",
        "* 6, segunda aparición: Ordena de manera ascendente según \"runtime\".\n",
        "\n",
        "7: Crea una nueva variable: \"age\", que sea 2024 - \"release_year\".\n",
        "* 7, segunda aparición: Ordena de manera ascendente según \"imbd_score\".\n",
        "\n",
        "8: Convierte la variable \"description\" a puras mayúsculas.\n",
        "* 8, segunda aparición: Ordena de manera ascendente según \"tmdb_popularity\".\n",
        "\n",
        "9: Haz un inner join con la tabla 'credits'. Filtra para mantener sólo las películas en donde apareció \"Meryl Streep\".\n",
        "* 9, segunda aparición: Ordena de manera descendente según \"imbd_score\".\n",
        "\n",
        "0: Lee la tabla 'credits'. Agrupa esa tabla para tener el conteo de actores por película/serie. Haz el join correspondiente para agregar el número de actores como una columna nueva a 'titles0.\n",
        "* 0, segunda aparición: Ordena de manera descendente según \"tmdb_popularity\".\n"
      ],
      "metadata": {
        "id": "w_ENr3iPXOPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit # y las demás que necesites\n"
      ],
      "metadata": {
        "id": "0dtuuRww-ekh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "X2lSnbMu90R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f90AdvR7d02L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}