{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertoarturomc/ProgramacionConcurrente/blob/main/29_Spark_con_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UQAJS17EEaI"
      },
      "source": [
        "### Programaci√≥n Concurrente\n",
        "## 29. Implementando Spark con R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"SparkR\")\n",
        "install.packages(\"sparklyr\")\n",
        "library(SparkR)\n",
        "library(sparklyr)"
      ],
      "metadata": {
        "id": "XA6E9kNe6vrb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "8dbcf0a8-2ec8-4711-c3fd-98b9b7523df9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n",
            "(as ‚Äòlib‚Äô is unspecified)\n",
            "\n",
            "Warning message:\n",
            "‚Äúpackage ‚ÄòSparkR‚Äô is not available for this version of R\n",
            "\n",
            "A version of this package for your version of R might be available elsewhere,\n",
            "see the ideas at\n",
            "https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages‚Äù\n",
            "Installing package into ‚Äò/usr/local/lib/R/site-library‚Äô\n",
            "(as ‚Äòlib‚Äô is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in library(SparkR): there is no package called ‚ÄòSparkR‚Äô\n",
          "traceback": [
            "Error in library(SparkR): there is no package called ‚ÄòSparkR‚Äô\nTraceback:\n",
            "1. stop(packageNotFoundError(package, lib.loc, sys.call()))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬°Spark tambi√©n se puede usar en R! Lo curioso es que aqu√≠ hay dos formas principales de implementaci√≥n: con `SparkR` y con `sparklyr`. Conozcamos qu√© son y c√≥mo funcionan..."
      ],
      "metadata": {
        "id": "tCcYSHtjtz5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî∂ Comparativo: SparkR vs sparklyr\n",
        "\n",
        "| Caracter√≠stica | **SparkR** | **sparklyr** |\n",
        "|----------------|-------------|--------------|\n",
        "| **Origen** | Desarrollado oficialmente por el proyecto **Apache Spark** | Desarrollado por **RStudio/Posit** |\n",
        "| **Estilo de sintaxis** | Similar a la API de DataFrames de PySpark | Basado en **dplyr** (sintaxis tidyverse) |\n",
        "| **Facilidad de uso** | Moderada (m√°s t√©cnica) | Muy amigable para usuarios de R |\n",
        "| **Integraci√≥n con el ecosistema R** | Limitada (poca integraci√≥n con tidyverse) | Excelente: funciona con **ggplot2**, **dplyr**, **tidymodels** |\n",
        "| **Soporte de MLlib (Machine Learning)** | Directo mediante funciones `spark.*` (p. ej. `spark.glm`) | Mediante funciones `ml_*` (p. ej. `ml_logistic_regression`) |\n",
        "| **Soporte de SQL** | Total (`sql(\"SELECT ...\")`) | Total (`spark_sql()`) |\n",
        "| **Interoperabilidad con Spark SQL / Hive** | Completa | Completa |\n",
        "| **Conectividad** | Integrada en Spark (sin instalaci√≥n extra) | Requiere el paquete CRAN `sparklyr` y conexi√≥n con `spark_connect()` |\n",
        "| **Curva de aprendizaje** | Similar a PySpark | M√°s intuitiva para usuarios de R |\n",
        "| **Visualizaci√≥n de resultados** | Limitada (requiere conversi√≥n a data.frame) | Compatible directamente con **ggplot2** tras `collect()` |\n",
        "| **Popularidad en la comunidad R** | Menor | Muy alta, est√°ndar de facto en R para Spark |\n",
        "| **Casos de uso ideales** | Integraci√≥n directa con entornos Spark corporativos | Exploraci√≥n, an√°lisis y machine learning distribuido desde RStudio |"
      ],
      "metadata": {
        "id": "18SKrzLptrdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://spark.apache.org/docs/latest/sparkr.html\n",
        "\n",
        "https://learn.microsoft.com/es-es/azure/databricks/sparkr/sparkr-vs-sparklyr"
      ],
      "metadata": {
        "id": "OsapYScwR527"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sparkR\n",
        "sparkR.session()"
      ],
      "metadata": {
        "id": "BfayZWVQSBX8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cce3a97d-04e2-4af2-e8d5-2bfe51d3b48c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in sparkR.session(): could not find function \"sparkR.session\"\n",
          "traceback": [
            "Error in sparkR.session(): could not find function \"sparkR.session\"\nTraceback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sparklyr\n",
        "\n",
        "library(sparklyr)\n",
        "\n",
        "spark_install()"
      ],
      "metadata": {
        "id": "ie3mYNjlufGR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc <- spark_connect(master = \"local\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "3UQSWWRxvSYN",
        "outputId": "4f6ba1bd-95a5-4f9b-fbc0-550f6fdde692"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error: Java 11 is only supported for Spark 3.0.0+\n",
          "traceback": [
            "Error: Java 11 is only supported for Spark 3.0.0+\nTraceback:\n",
            "1. spark_connect_method(x = obj_method, method = method, master = master, \n .     spark_home = spark_home, config = config, app_name = app_name, \n .     version = version, extensions = extensions, scala_version = scala_version, \n .     ...)",
            "2. spark_connect_method.default(x = obj_method, method = method, \n .     master = master, spark_home = spark_home, config = config, \n .     app_name = app_name, version = version, extensions = extensions, \n .     scala_version = scala_version, ...)",
            "3. shell_connection(master = master, spark_home = spark_home, method = method, \n .     app_name = app_name, version = version, hadoop_version = hadoop_version, \n .     shell_args = shell_args, config = config, service = spark_config_value(config, \n .         \"sparklyr.gateway.service\", FALSE), remote = spark_config_value(config, \n .         \"sparklyr.gateway.remote\", spark_master_is_yarn_cluster(master, \n .             config)), extensions = extensions, batch = NULL, \n .     scala_version = scala_version)",
            "4. validate_java_version(master, spark_home)",
            "5. stop(\"Java 11 is only supported for Spark 3.0.0+\", call. = FALSE)",
            "6. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"Java 11 is only supported for Spark 3.0.0+\", base::quote(NULL))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VYW0AT8IvcuH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}